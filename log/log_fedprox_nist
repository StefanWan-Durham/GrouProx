Arguments:
	       batch_size : 10
	clients_per_round : 10
	          dataset : nist
	     drop_percent : 0.0
	       eval_every : 1
	    learning_rate : 0.003
	            model : mclr
	     model_params : (26,)
	               mu : 1.0
	       num_epochs : 20
	        num_iters : 1
	       num_rounds : 200
	        optimizer : fedprox
	             seed : 0
Using Federated prox to Train
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/163.18k flops)
  dense/kernel/Initializer/random_uniform (20.38k/40.77k flops)
    dense/kernel/Initializer/random_uniform/mul (20.38k/20.38k flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  PGD/update_dense/kernel/AssignSub (20.38k/20.38k flops)
  PGD/update_dense/kernel/mul (20.38k/20.38k flops)
  PGD/update_dense/kernel/mul_1 (20.38k/20.38k flops)
  PGD/update_dense/kernel/sub (20.38k/20.38k flops)
  dense/kernel/Regularizer/Square (20.38k/20.38k flops)
  dense/kernel/Regularizer/Sum (20.38k/20.38k flops)
  PGD/update_dense/bias/AssignSub (26/26 flops)
  PGD/update_dense/bias/mul (26/26 flops)
  PGD/update_dense/bias/mul_1 (26/26 flops)
  PGD/update_dense/bias/sub (26/26 flops)
  dense/kernel/Regularizer/mul (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
200 Clients in Total
Training with 10 workers ---
At round 0 accuracy: 0.0
At round 0 training accuracy: 0.0
At round 0 training loss: 5.140008765229296
gradient difference: 178.47573690999548
At round 1 accuracy: 0.10187110187110188
At round 1 training accuracy: 0.10383046099506729
At round 1 training loss: 3.3363136750366387
gradient difference: 176.12416241295173
At round 2 accuracy: 0.13201663201663202
At round 2 training accuracy: 0.13701966993483952
At round 2 training loss: 2.630214856469626
gradient difference: 177.08341126915042
At round 3 accuracy: 0.13565488565488565
At round 3 training accuracy: 0.1278850252725169
At round 3 training loss: 2.6578733003224433
gradient difference: 175.29996023066695
At round 4 accuracy: 0.1606029106029106
At round 4 training accuracy: 0.16576335180561477
At round 4 training loss: 3.3176064763723385
gradient difference: 176.5151576639779
At round 5 accuracy: 0.19230769230769232
At round 5 training accuracy: 0.19298459289933623
At round 5 training loss: 2.789623942192823
gradient difference: 172.9371032196338
At round 6 accuracy: 0.2718295218295218
At round 6 training accuracy: 0.2868887400280129
At round 6 training loss: 2.162210255118992
gradient difference: 171.2633586814331
At round 7 accuracy: 0.21621621621621623
At round 7 training accuracy: 0.22593021131477986
At round 7 training loss: 2.102990938767643
gradient difference: 169.0322190457683
At round 8 accuracy: 0.24272349272349272
At round 8 training accuracy: 0.24675720114487545
At round 8 training loss: 2.200159397988261
gradient difference: 168.59651600404794
At round 9 accuracy: 0.14760914760914762
At round 9 training accuracy: 0.13988185859570063
At round 9 training loss: 2.8264905868614134
gradient difference: 170.0719516381228
At round 10 accuracy: 0.2946985446985447
At round 10 training accuracy: 0.2934656841848852
At round 10 training loss: 2.5297722542273577
gradient difference: 166.3022269479105
At round 11 accuracy: 0.382016632016632
At round 11 training accuracy: 0.3831678947688935
At round 11 training loss: 1.9154776960536932
gradient difference: 163.15595394208967
At round 12 accuracy: 0.27494802494802495
At round 12 training accuracy: 0.2742829303940077
At round 12 training loss: 3.1684614582079482
gradient difference: 166.461789523305
At round 13 accuracy: 0.2448024948024948
At round 13 training accuracy: 0.24450398879483587
At round 13 training loss: 3.085526064077297
gradient difference: 165.55547757559162
At round 14 accuracy: 0.3627858627858628
At round 14 training accuracy: 0.3548504963156933
At round 14 training loss: 1.8038653126370419
gradient difference: 154.23993012775802
At round 15 accuracy: 0.26195426195426197
At round 15 training accuracy: 0.2508373424273796
At round 15 training loss: 2.0572969917475428
gradient difference: 158.23576726348182
At round 16 accuracy: 0.22972972972972974
At round 16 training accuracy: 0.2398757688325924
At round 16 training loss: 2.1240714147127067
gradient difference: 164.32591168596434
At round 17 accuracy: 0.3009355509355509
At round 17 training accuracy: 0.2979721088849644
At round 17 training loss: 2.117718032409529
gradient difference: 157.2719595290217
At round 18 accuracy: 0.45686070686070684
At round 18 training accuracy: 0.44376103769563363
At round 18 training loss: 1.7223749293906994
gradient difference: 152.83009073862684
At round 19 accuracy: 0.3414760914760915
At round 19 training accuracy: 0.34924791425613544
At round 19 training loss: 1.7615951311500446
gradient difference: 151.68863957779587
At round 20 accuracy: 0.42411642411642414
At round 20 training accuracy: 0.4337129285670787
At round 20 training loss: 1.8104076902378956
gradient difference: 151.64787793021188
At round 21 accuracy: 0.1995841995841996
At round 21 training accuracy: 0.19834358443456548
At round 21 training loss: 2.057092919567312
gradient difference: 154.35936191292433
At round 22 accuracy: 0.33264033264033266
At round 22 training accuracy: 0.34364533219657756
At round 22 training loss: 1.703428321685144
gradient difference: 151.59351799493479
At round 23 accuracy: 0.5904365904365905
At round 23 training accuracy: 0.5877230375738384
At round 23 training loss: 1.5861063205646282
gradient difference: 141.14851368190406
At round 24 accuracy: 0.3581081081081081
At round 24 training accuracy: 0.34961330004262836
At round 24 training loss: 1.7830885530323939
gradient difference: 143.44119191636048
At round 25 accuracy: 0.24376299376299376
At round 25 training accuracy: 0.2332988246757201
At round 25 training loss: 1.9247287981555607
gradient difference: 150.88214488194637
At round 26 accuracy: 0.48804573804573803
At round 26 training accuracy: 0.4797515376651848
At round 26 training loss: 1.664324649060791
gradient difference: 145.41220392240572
At round 27 accuracy: 0.3388773388773389
At round 27 training accuracy: 0.3283600267949577
At round 27 training loss: 2.0003578017606025
gradient difference: 148.53091939471523
At round 28 accuracy: 0.39449064449064447
At round 28 training accuracy: 0.38718713842031544
At round 28 training loss: 1.6383787834116548
gradient difference: 140.94268735180043
At round 29 accuracy: 0.4475051975051975
At round 29 training accuracy: 0.44223859691857986
At round 29 training loss: 1.8860141745576846
gradient difference: 141.39555072055165
At round 30 accuracy: 0.32744282744282743
At round 30 training accuracy: 0.3196516655502101
At round 30 training loss: 1.9097305022547142
gradient difference: 144.674197174587
At round 31 accuracy: 0.5041580041580042
At round 31 training accuracy: 0.5010657085439376
At round 31 training loss: 1.552708612308818
gradient difference: 135.938488710775
At round 32 accuracy: 0.498960498960499
At round 32 training accuracy: 0.5035625114183059
At round 32 training loss: 1.5246845942366523
gradient difference: 136.96379703849465
At round 33 accuracy: 0.3482328482328482
At round 33 training accuracy: 0.36087936179282626
At round 33 training loss: 1.698673520390339
gradient difference: 146.5007938327195
At round 34 accuracy: 0.42723492723492723
At round 34 training accuracy: 0.4299372754399854
At round 34 training loss: 1.5443949454936061
gradient difference: 140.44011665225196
At round 35 accuracy: 0.49064449064449067
At round 35 training accuracy: 0.47238292430424456
At round 35 training loss: 1.6166115660998746
gradient difference: 137.1889680322902
At round 36 accuracy: 0.3123700623700624
At round 36 training accuracy: 0.31021253273247673
At round 36 training loss: 2.089351077748669
gradient difference: 143.87397632514148
At round 37 accuracy: 0.3705821205821206
At round 37 training accuracy: 0.3734851714268315
At round 37 training loss: 1.729223289905574
gradient difference: 139.49034412864947
At round 38 accuracy: 0.33627858627858626
At round 38 training accuracy: 0.3491870166250533
At round 38 training loss: 1.7358881244197135
gradient difference: 145.2117728882708
At round 39 accuracy: 0.6211018711018711
At round 39 training accuracy: 0.6181109554838317
At round 39 training loss: 1.421998392739966
gradient difference: 125.62414533917757
At round 40 accuracy: 0.5748440748440748
At round 40 training accuracy: 0.5631203946166494
At round 40 training loss: 1.4329910510190766
gradient difference: 128.6100962803131
At round 41 accuracy: 0.4158004158004158
At round 41 training accuracy: 0.41818403264113024
At round 41 training loss: 1.7046195637961266
gradient difference: 137.005353024471
At round 42 accuracy: 0.3981288981288981
At round 42 training accuracy: 0.40935387613421836
At round 42 training loss: 1.542861710573461
gradient difference: 135.67209156731016
At round 43 accuracy: 0.45686070686070684
At round 43 training accuracy: 0.4394373058888009
At round 43 training loss: 1.5920470991172975
gradient difference: 131.05363266904507
At round 44 accuracy: 0.30613305613305614
At round 44 training accuracy: 0.3184337129285671
At round 44 training loss: 1.8152931268232166
gradient difference: 149.49278019468298
At round 45 accuracy: 0.3518711018711019
At round 45 training accuracy: 0.34413251324523475
At round 45 training loss: 1.8597408700683333
gradient difference: 142.76532028366577
At round 46 accuracy: 0.5311850311850311
At round 46 training accuracy: 0.5291395164728092
At round 46 training loss: 1.5007733724111616
gradient difference: 129.55189530713469
At round 47 accuracy: 0.5665280665280665
At round 47 training accuracy: 0.560136410693624
At round 47 training loss: 1.3589017834800452
gradient difference: 122.04643696774384
At round 48 accuracy: 0.6330561330561331
At round 48 training accuracy: 0.6269411119907435
At round 48 training loss: 1.364921265830004
gradient difference: 121.97635328547995
At round 49 accuracy: 0.4391891891891892
At round 49 training accuracy: 0.4413251324523476
At round 49 training loss: 1.5130190906908834
gradient difference: 128.82515286067985
At round 50 accuracy: 0.6034303534303534
At round 50 training accuracy: 0.5884538091468242
At round 50 training loss: 1.4526073295947703
gradient difference: 124.81306223201314
At round 51 accuracy: 0.5358627858627859
At round 51 training accuracy: 0.5312100359296024
At round 51 training loss: 1.419231784266768
gradient difference: 121.70903779476643
At round 52 accuracy: 0.21153846153846154
At round 52 training accuracy: 0.19353267157907558
At round 52 training loss: 2.043871791112598
gradient difference: 147.47453822654265
At round 53 accuracy: 0.3393970893970894
At round 53 training accuracy: 0.35174471713050365
At round 53 training loss: 2.262897244145349
gradient difference: 158.34066071101842
At round 54 accuracy: 0.47297297297297297
At round 54 training accuracy: 0.47786371110163817
At round 54 training loss: 1.4515187673719434
gradient difference: 127.8523022969079
At round 55 accuracy: 0.3295218295218295
At round 55 training accuracy: 0.32610681444491807
At round 55 training loss: 1.6598838995975407
gradient difference: 125.961522397279
At round 56 accuracy: 0.5348232848232848
At round 56 training accuracy: 0.5277997685890019
At round 56 training loss: 1.3780922871524266
gradient difference: 115.26659876049175
At round 57 accuracy: 0.5592515592515592
At round 57 training accuracy: 0.5634248827720602
At round 57 training loss: 1.3253092884647157
gradient difference: 115.2335996767556
At round 58 accuracy: 0.5083160083160083
At round 58 training accuracy: 0.5061202119237561
At round 58 training loss: 1.3248630393132914
gradient difference: 116.6602567585583
At round 59 accuracy: 0.36642411642411643
At round 59 training accuracy: 0.3513793313440107
At round 59 training loss: 1.6372296082451518
gradient difference: 123.04716287221041
At round 60 accuracy: 0.38513513513513514
At round 60 training accuracy: 0.3680043846294379
At round 60 training loss: 1.52160659128054
gradient difference: 120.32519842809502
At round 61 accuracy: 0.5571725571725572
At round 61 training accuracy: 0.5584312770233238
At round 61 training loss: 1.3322120780747655
gradient difference: 116.8867956254273
At round 62 accuracy: 0.3591476091476091
At round 62 training accuracy: 0.36623835332805554
At round 62 training loss: 2.1349270116429144
gradient difference: 154.9303125005784
At round 63 accuracy: 0.5233887733887734
At round 63 training accuracy: 0.5298702880457951
At round 63 training loss: 1.429208647946363
gradient difference: 120.163146912403
At round 64 accuracy: 0.44854469854469853
At round 64 training accuracy: 0.4510078557944096
At round 64 training loss: 1.4486708010214342
gradient difference: 120.99549392782762
At round 65 accuracy: 0.5841995841995842
At round 65 training accuracy: 0.5896717617684673
At round 65 training loss: 1.3589209630358532
gradient difference: 115.80568848755216
At round 66 accuracy: 0.5415800415800416
At round 66 training accuracy: 0.5316363193471774
At round 66 training loss: 1.4220525121058714
gradient difference: 121.20622080840127
At round 67 accuracy: 0.3591476091476091
At round 67 training accuracy: 0.34291456062359177
At round 67 training loss: 1.6108024200294901
gradient difference: 123.59228521460892
At round 68 accuracy: 0.3503118503118503
At round 68 training accuracy: 0.3563729370927471
At round 68 training loss: 2.1484051964839943
gradient difference: 154.8800727190857
At round 69 accuracy: 0.40384615384615385
At round 69 training accuracy: 0.40265513671518177
At round 69 training loss: 1.7005636432463282
gradient difference: 137.32950847669565
At round 70 accuracy: 0.3991683991683992
At round 70 training accuracy: 0.3927288228487912
At round 70 training loss: 1.5584312298724599
gradient difference: 124.77267940758897
At round 71 accuracy: 0.5057172557172557
At round 71 training accuracy: 0.5075817550697278
At round 71 training loss: 1.317167410068815
gradient difference: 112.82171950470543
At round 72 accuracy: 0.5764033264033264
At round 72 training accuracy: 0.5696364411424396
At round 72 training loss: 1.2927240249765217
gradient difference: 114.19057234349921
At round 73 accuracy: 0.4126819126819127
At round 73 training accuracy: 0.4122160647950795
At round 73 training loss: 1.510963096636656
gradient difference: 119.7375570659069
At round 74 accuracy: 0.591995841995842
At round 74 training accuracy: 0.5989890993240363
At round 74 training loss: 1.2605595544727426
gradient difference: 110.9274705855583
At round 75 accuracy: 0.617983367983368
At round 75 training accuracy: 0.6243225138542111
At round 75 training loss: 1.2285238128509601
gradient difference: 108.10128077735622
At round 76 accuracy: 0.6616424116424117
At round 76 training accuracy: 0.6657329029900737
At round 76 training loss: 1.194750946634224
gradient difference: 103.13937395697238
At round 77 accuracy: 0.5093555093555093
At round 77 training accuracy: 0.4945496620181475
At round 77 training loss: 1.442637885477473
gradient difference: 112.54680853727268
At round 78 accuracy: 0.6330561330561331
At round 78 training accuracy: 0.6329090798367943
At round 78 training loss: 1.1613252861738916
gradient difference: 101.44924235342174
At round 79 accuracy: 0.5758835758835759
At round 79 training accuracy: 0.5737774800560258
At round 79 training loss: 1.311310214752707
gradient difference: 107.24566658072465
At round 80 accuracy: 0.4319126819126819
At round 80 training accuracy: 0.4226295597101273
At round 80 training loss: 1.4487234301133247
gradient difference: 114.63302054985876
At round 81 accuracy: 0.461018711018711
At round 81 training accuracy: 0.46623226356494735
At round 81 training loss: 1.4943516195023672
gradient difference: 119.51419302818182
At round 82 accuracy: 0.5566528066528067
At round 82 training accuracy: 0.5379087753486389
At round 82 training loss: 1.336396674793056
gradient difference: 111.70056560801122
At round 83 accuracy: 0.524948024948025
At round 83 training accuracy: 0.52378052493758
At round 83 training loss: 1.3366314391802074
gradient difference: 108.07730483849758
At round 84 accuracy: 0.43295218295218296
At round 84 training accuracy: 0.4312770233237927
At round 84 training loss: 1.3905045511744925
gradient difference: 111.71559850554621
At round 85 accuracy: 0.5795218295218295
At round 85 training accuracy: 0.5709761890262469
At round 85 training loss: 1.2524599891059995
gradient difference: 105.75150943306224
At round 86 accuracy: 0.6621621621621622
At round 86 training accuracy: 0.665854698252238
At round 86 training loss: 1.1575312886311564
gradient difference: 99.42786526750405
At round 87 accuracy: 0.5753638253638254
At round 87 training accuracy: 0.5718896534924791
At round 87 training loss: 1.2829069571571716
gradient difference: 110.49658565468994
At round 88 accuracy: 0.5083160083160083
At round 88 training accuracy: 0.5094086840021923
At round 88 training loss: 1.348057557427123
gradient difference: 113.01958433973077
At round 89 accuracy: 0.4656964656964657
At round 89 training accuracy: 0.4557578710188174
At round 89 training loss: 1.4570467053907419
gradient difference: 119.9093466214125
At round 90 accuracy: 0.6543659043659044
At round 90 training accuracy: 0.6556238962304366
At round 90 training loss: 1.1890226512753523
gradient difference: 103.43996411185498
At round 91 accuracy: 0.5862785862785863
At round 91 training accuracy: 0.5878448328360026
At round 91 training loss: 1.2075069736809338
gradient difference: 104.37431493475138
At round 92 accuracy: 0.632016632016632
At round 92 training accuracy: 0.6365629377017235
At round 92 training loss: 1.1221031443506913
gradient difference: 99.83102190886711
At round 93 accuracy: 0.6340956340956341
At round 93 training accuracy: 0.6411911576639668
At round 93 training loss: 1.147579229663506
gradient difference: 98.2031040129295
At round 94 accuracy: 0.5623700623700624
At round 94 training accuracy: 0.5605626941111991
At round 94 training loss: 1.2851788705924594
gradient difference: 102.6859362029306
At round 95 accuracy: 0.6138253638253638
At round 95 training accuracy: 0.6003897448389258
At round 95 training loss: 1.2685605146934138
gradient difference: 103.28406640555448
At round 96 accuracy: 0.5327442827442828
At round 96 training accuracy: 0.5296875951525486
At round 96 training loss: 1.2809777913132914
gradient difference: 104.22976786783164
At round 97 accuracy: 0.5925155925155925
At round 97 training accuracy: 0.5835819986602521
At round 97 training loss: 1.2151754036047566
gradient difference: 104.78543067136422
At round 98 accuracy: 0.49532224532224534
At round 98 training accuracy: 0.4976554412033372
At round 98 training loss: 1.3746613917390116
gradient difference: 113.88068195848206
At round 99 accuracy: 0.5935550935550935
At round 99 training accuracy: 0.5897935570306315
At round 99 training loss: 1.2239644047759655
gradient difference: 103.66935955584229
At round 100 accuracy: 0.4630977130977131
At round 100 training accuracy: 0.4698252237987942
At round 100 training loss: 1.3458538066781138
gradient difference: 110.73518207375747
At round 101 accuracy: 0.6777546777546778
At round 101 training accuracy: 0.6827233420619938
At round 101 training loss: 1.08457897596343
gradient difference: 93.43921974102345
At round 102 accuracy: 0.5540540540540541
At round 102 training accuracy: 0.5434504597771147
At round 102 training loss: 1.26191007116921
gradient difference: 102.03870797060773
At round 103 accuracy: 0.45582120582120583
At round 103 training accuracy: 0.451982217891724
At round 103 training loss: 1.4387318764496035
gradient difference: 104.0153011369548
At round 104 accuracy: 0.48596673596673595
At round 104 training accuracy: 0.49095670178430056
At round 104 training loss: 1.2984868177077735
gradient difference: 112.03050565155434
At round 105 accuracy: 0.3700623700623701
At round 105 training accuracy: 0.35947871627793676
At round 105 training loss: 1.7557050961719551
gradient difference: 132.6535813785593
At round 106 accuracy: 0.5914760914760915
At round 106 training accuracy: 0.5816332744656233
At round 106 training loss: 1.2531490254747717
gradient difference: 95.73835231554018
At round 107 accuracy: 0.44386694386694386
At round 107 training accuracy: 0.4450398879483588
At round 107 training loss: 1.4697901024124986
gradient difference: 115.51126525415206
At round 108 accuracy: 0.4714137214137214
At round 108 training accuracy: 0.48450155288959257
At round 108 training loss: 1.3691232661680852
gradient difference: 116.39555379189638
At round 109 accuracy: 0.590956340956341
At round 109 training accuracy: 0.579501857377748
At round 109 training loss: 1.229134991230537
gradient difference: 100.60122320962135
At round 110 accuracy: 0.5982328482328483
At round 110 training accuracy: 0.5999025637902685
At round 110 training loss: 1.1897175025162443
gradient difference: 98.76451012452539
At round 111 accuracy: 0.6975051975051975
At round 111 training accuracy: 0.7014189148042141
At round 111 training loss: 1.1243349671015372
gradient difference: 92.67920159709084
At round 112 accuracy: 0.44594594594594594
At round 112 training accuracy: 0.43608793617928265
At round 112 training loss: 1.4857346417298307
gradient difference: 112.19419564820988
At round 113 accuracy: 0.6117463617463618
At round 113 training accuracy: 0.6104987515985628
At round 113 training loss: 1.1822267612163901
gradient difference: 98.56104823483754
At round 114 accuracy: 0.36746361746361744
At round 114 training accuracy: 0.37945313927288227
At round 114 training loss: 2.0297592370789306
gradient difference: 146.9650556845314
At round 115 accuracy: 0.5369022869022869
At round 115 training accuracy: 0.5449729005541685
At round 115 training loss: 1.343536019039411
gradient difference: 113.06199068520495
At round 116 accuracy: 0.49324324324324326
At round 116 training accuracy: 0.4999695511844589
At round 116 training loss: 1.2749935066077112
gradient difference: 109.8941031807591
At round 117 accuracy: 0.4968814968814969
At round 117 training accuracy: 0.5035625114183059
At round 117 training loss: 1.3297169751215268
gradient difference: 110.41293687187806
At round 118 accuracy: 0.6735966735966736
At round 118 training accuracy: 0.6732842092442604
At round 118 training loss: 1.12085847170473
gradient difference: 94.06047439869785
At round 119 accuracy: 0.48544698544698545
At round 119 training accuracy: 0.4797515376651848
At round 119 training loss: 1.379763563613161
gradient difference: 114.1355291849588
At round 120 accuracy: 0.6533264033264033
At round 120 training accuracy: 0.6525790146763291
At round 120 training loss: 1.1222347951307052
gradient difference: 89.92589215000552
At round 121 accuracy: 0.46517671517671516
At round 121 training accuracy: 0.47585408927592715
At round 121 training loss: 1.3741885363732582
gradient difference: 112.88132354386453
At round 122 accuracy: 0.30353430353430355
At round 122 training accuracy: 0.30284391937153643
At round 122 training loss: 1.9520129676978355
gradient difference: 142.6646011683093
At round 123 accuracy: 0.3581081081081081
At round 123 training accuracy: 0.36301077888070155
At round 123 training loss: 1.668952756282016
gradient difference: 131.96328902051596
At round 124 accuracy: 0.6330561330561331
At round 124 training accuracy: 0.6326045916813836
At round 124 training loss: 1.1148612748403424
gradient difference: 90.5039492949541
At round 125 accuracy: 0.6278586278586279
At round 125 training accuracy: 0.6374764021679556
At round 125 training loss: 1.0621541381121828
gradient difference: 92.1081247071372
At round 126 accuracy: 0.6159043659043659
At round 126 training accuracy: 0.6193898057365569
At round 126 training loss: 1.116681493288358
gradient difference: 96.62373523115693
At round 127 accuracy: 0.6704781704781705
At round 127 training accuracy: 0.6791303818281469
At round 127 training loss: 1.0679547811903332
gradient difference: 90.71017825277364
At round 128 accuracy: 0.525987525987526
At round 128 training accuracy: 0.5123926679252178
At round 128 training loss: 1.3563213108460104
gradient difference: 101.45814100057247
At round 129 accuracy: 0.5150727650727651
At round 129 training accuracy: 0.5008830156506912
At round 129 training loss: 1.389580299178631
gradient difference: 102.16903380664662
At round 130 accuracy: 0.5436590436590436
At round 130 training accuracy: 0.5314536264539309
At round 130 training loss: 1.3063858203958794
gradient difference: 102.2662650301323
At round 131 accuracy: 0.5051975051975052
At round 131 training accuracy: 0.5163510139455575
At round 131 training loss: 1.2763726879440978
gradient difference: 103.65292310799245
At round 132 accuracy: 0.46205821205821207
At round 132 training accuracy: 0.45441812313501007
At round 132 training loss: 1.6212540271738314
gradient difference: 120.24907540991398
At round 133 accuracy: 0.5769230769230769
At round 133 training accuracy: 0.5854698252237988
At round 133 training loss: 1.2396244667681435
gradient difference: 98.00574011509161
At round 134 accuracy: 0.6164241164241164
At round 134 training accuracy: 0.6191462152122282
At round 134 training loss: 1.1506560731294218
gradient difference: 85.90783712306425
At round 135 accuracy: 0.6075883575883576
At round 135 training accuracy: 0.594421776992875
At round 135 training loss: 1.240881467374072
gradient difference: 90.4571578883691
At round 136 accuracy: 0.6382536382536382
At round 136 training accuracy: 0.6302295840691797
At round 136 training loss: 1.1122685707876434
gradient difference: 89.7633486770717
At round 137 accuracy: 0.7063409563409564
At round 137 training accuracy: 0.7061689300286219
At round 137 training loss: 0.9681396301978471
gradient difference: 80.17003126746968
At round 138 accuracy: 0.5893970893970893
At round 138 training accuracy: 0.6003288472078436
At round 138 training loss: 1.1741451427188965
gradient difference: 86.13603431960452
At round 139 accuracy: 0.47193347193347196
At round 139 training accuracy: 0.4658668777784544
At round 139 training loss: 1.4706320155154018
gradient difference: 109.4840855628622
At round 140 accuracy: 0.40436590436590436
At round 140 training accuracy: 0.40478655380305706
At round 140 training loss: 1.6184084342286615
gradient difference: 122.24373104490307
At round 141 accuracy: 0.45114345114345117
At round 141 training accuracy: 0.45673223311613176
At round 141 training loss: 1.3904979329010172
gradient difference: 113.94404811647455
At round 142 accuracy: 0.3082120582120582
At round 142 training accuracy: 0.3030266122647829
At round 142 training loss: 1.8291078350621799
gradient difference: 124.33643989972072
At round 143 accuracy: 0.4527027027027027
At round 143 training accuracy: 0.4518604226295597
At round 143 training loss: 1.5435006176827923
gradient difference: 112.44817391681799
At round 144 accuracy: 0.46517671517671516
At round 144 training accuracy: 0.46099506729188233
At round 144 training loss: 1.4403402968813734
gradient difference: 111.99787529275567
At round 145 accuracy: 0.6153846153846154
At round 145 training accuracy: 0.6266366238353328
At round 145 training loss: 1.11813676968706
gradient difference: 86.54117715320788
At round 146 accuracy: 0.5701663201663202
At round 146 training accuracy: 0.5587966628098167
At round 146 training loss: 1.2817583013942766
gradient difference: 92.6653313195038
At round 147 accuracy: 0.47505197505197505
At round 147 training accuracy: 0.47749832531514524
At round 147 training loss: 1.3445112901656349
gradient difference: 105.42742685544849
At round 148 accuracy: 0.38253638253638256
At round 148 training accuracy: 0.39017112234334084
At round 148 training loss: 1.9350478755492007
gradient difference: 141.81545073653714
At round 149 accuracy: 0.6554054054054054
At round 149 training accuracy: 0.6595213446196942
At round 149 training loss: 1.0518437124501554
gradient difference: 83.93145488906426
At round 150 accuracy: 0.58004158004158
At round 150 training accuracy: 0.5934474148955605
At round 150 training loss: 1.0949337507479737
gradient difference: 93.16149467677471
At round 151 accuracy: 0.7307692307692307
At round 151 training accuracy: 0.7321113208696182
At round 151 training loss: 0.9389874393913402
gradient difference: 78.16957764116562
At round 152 accuracy: 0.5945945945945946
At round 152 training accuracy: 0.5959442177699288
At round 152 training loss: 1.152050588017484
gradient difference: 91.87098485548047
At round 153 accuracy: 0.5665280665280665
At round 153 training accuracy: 0.5865050849521953
At round 153 training loss: 1.2114962001559317
gradient difference: 94.59919171940054
At round 154 accuracy: 0.6003118503118503
At round 154 training accuracy: 0.6031301382376225
At round 154 training loss: 1.106901271736627
gradient difference: 92.50612466896297
At round 155 accuracy: 0.5862785862785863
At round 155 training accuracy: 0.5826076365629377
At round 155 training loss: 1.2507698494303743
gradient difference: 97.72237073221133
At round 156 accuracy: 0.5639293139293139
At round 156 training accuracy: 0.5664088666950856
At round 156 training loss: 1.2175710771248043
gradient difference: 90.71218276501102
At round 157 accuracy: 0.5764033264033264
At round 157 training accuracy: 0.5860788015346203
At round 157 training loss: 1.1500558422856946
gradient difference: 95.23341084533078
At round 158 accuracy: 0.5192307692307693
At round 158 training accuracy: 0.5251202728213873
At round 158 training loss: 1.2133660949591953
gradient difference: 101.70050094160032
At round 159 accuracy: 0.49636174636174635
At round 159 training accuracy: 0.5038669995737166
At round 159 training loss: 1.3607786998727145
gradient difference: 114.94326543852276
At round 160 accuracy: 0.5353430353430353
At round 160 training accuracy: 0.5373606966688996
At round 160 training loss: 1.2962296327704104
gradient difference: 103.13672849119197
At round 161 accuracy: 0.6288981288981289
At round 161 training accuracy: 0.6373546069057914
At round 161 training loss: 1.0023796578525415
gradient difference: 85.13126914986086
At round 162 accuracy: 0.4407484407484408
At round 162 training accuracy: 0.43633152670361125
At round 162 training loss: 1.428094869372572
gradient difference: 107.61083264517045
At round 163 accuracy: 0.4527027027027027
At round 163 training accuracy: 0.4525302965714634
At round 163 training loss: 1.3840390972406984
gradient difference: 113.76751035564645
At round 164 accuracy: 0.6668399168399168
At round 164 training accuracy: 0.6728579258266854
At round 164 training loss: 1.0218329691406318
gradient difference: 87.47916161618876
At round 165 accuracy: 0.4625779625779626
At round 165 training accuracy: 0.45922903599049997
At round 165 training loss: 1.3975602648528411
gradient difference: 109.43366557109333
At round 166 accuracy: 0.4407484407484408
At round 166 training accuracy: 0.444309116375373
At round 166 training loss: 1.7453013621427191
gradient difference: 131.06215770352662
At round 167 accuracy: 0.6865904365904366
At round 167 training accuracy: 0.684854759149869
At round 167 training loss: 1.0420390007723976
gradient difference: 82.80970409785648
At round 168 accuracy: 0.5161122661122661
At round 168 training accuracy: 0.5089824005846173
At round 168 training loss: 1.2693921589080415
gradient difference: 100.29490603146944
At round 169 accuracy: 0.632016632016632
At round 169 training accuracy: 0.6182936483770781
At round 169 training loss: 1.115180495145238
gradient difference: 84.94848409752706
At round 170 accuracy: 0.5628898128898129
At round 170 training accuracy: 0.5546556238962305
At round 170 training loss: 1.1667389580668577
gradient difference: 88.29609398281993
At round 171 accuracy: 0.6278586278586279
At round 171 training accuracy: 0.6352840874489982
At round 171 training loss: 1.0848256729311356
gradient difference: 81.74599654177844
At round 172 accuracy: 0.6044698544698545
At round 172 training accuracy: 0.6097070823944949
At round 172 training loss: 1.0790438088133842
gradient difference: 89.86248737797588
At round 173 accuracy: 0.66008316008316
At round 173 training accuracy: 0.6660982887765666
At round 173 training loss: 1.0470330228226084
gradient difference: 80.22625353552324
At round 174 accuracy: 0.4391891891891892
At round 174 training accuracy: 0.44796297424030207
At round 174 training loss: 1.4713054954820526
gradient difference: 116.33178648557521
At round 175 accuracy: 0.501039501039501
At round 175 training accuracy: 0.5178125570915292
At round 175 training loss: 1.2711979702553355
gradient difference: 105.56741668363435
At round 176 accuracy: 0.5841995841995842
At round 176 training accuracy: 0.5791973692223372
At round 176 training loss: 1.1263824367623376
gradient difference: 90.04910918075562
At round 177 accuracy: 0.6055093555093555
At round 177 training accuracy: 0.5920467693806711
At round 177 training loss: 1.1379820593279932
gradient difference: 87.48219092361245
At round 178 accuracy: 0.6980249480249481
At round 178 training accuracy: 0.6877778454418123
At round 178 training loss: 1.021250541659106
gradient difference: 79.0319158484426
At round 179 accuracy: 0.6055093555093555
At round 179 training accuracy: 0.6048961695390049
At round 179 training loss: 1.0964365566984091
gradient difference: 83.79400676537867
At round 180 accuracy: 0.5265072765072765
At round 180 training accuracy: 0.5249375799281408
At round 180 training loss: 1.3935575230037691
gradient difference: 100.68846419491425
At round 181 accuracy: 0.5327442827442828
At round 181 training accuracy: 0.5447293100298398
At round 181 training loss: 1.327708361772576
gradient difference: 107.1053435194324
At round 182 accuracy: 0.4501039501039501
At round 182 training accuracy: 0.45618415443639243
At round 182 training loss: 1.593979128664267
gradient difference: 123.0824787473704
At round 183 accuracy: 0.47713097713097713
At round 183 training accuracy: 0.47859448267462396
At round 183 training loss: 1.352808526506429
gradient difference: 108.81453716853349
At round 184 accuracy: 0.6377338877338877
At round 184 training accuracy: 0.6376590950612021
At round 184 training loss: 1.0681148427760048
gradient difference: 80.60388107865654
At round 185 accuracy: 0.4890852390852391
At round 185 training accuracy: 0.4800560258205956
At round 185 training loss: 1.3361634308198114
gradient difference: 99.84960496756673
At round 186 accuracy: 0.659043659043659
At round 186 training accuracy: 0.6704220205833993
At round 186 training loss: 0.9855745552638207
gradient difference: 81.49662665849065
At round 187 accuracy: 0.5956340956340956
At round 187 training accuracy: 0.5893063759819743
At round 187 training loss: 1.141652125903107
gradient difference: 87.0595697182335
At round 188 accuracy: 0.42723492723492723
At round 188 training accuracy: 0.4393764082577188
At round 188 training loss: 1.5440244006430737
gradient difference: 123.20079108274817
At round 189 accuracy: 0.6133056133056133
At round 189 training accuracy: 0.6114731136958772
At round 189 training loss: 1.1001445987253835
gradient difference: 89.01257869358388
At round 190 accuracy: 0.643970893970894
At round 190 training accuracy: 0.642043724499117
At round 190 training loss: 1.0013128809676697
gradient difference: 81.07722053990591
At round 191 accuracy: 0.5265072765072765
At round 191 training accuracy: 0.5227452652091834
At round 191 training loss: 1.2884211068214435
gradient difference: 101.2182034087985
At round 192 accuracy: 0.6211018711018711
At round 192 training accuracy: 0.6308385603800012
At round 192 training loss: 1.0806127062694548
gradient difference: 83.72663838928301
At round 193 accuracy: 0.6943866943866944
At round 193 training accuracy: 0.7047682845137324
At round 193 training loss: 0.8922160774402225
gradient difference: 73.67111329803124
At round 194 accuracy: 0.6434511434511434
At round 194 training accuracy: 0.6636014859021984
At round 194 training loss: 1.0227288550933034
gradient difference: 78.12382680642123
At round 195 accuracy: 0.5343035343035343
At round 195 training accuracy: 0.5195176907618294
At round 195 training loss: 1.2983615408924274
gradient difference: 100.55838354650376
At round 196 accuracy: 0.6491683991683992
At round 196 training accuracy: 0.644905913159978
At round 196 training loss: 1.1157650204137068
gradient difference: 78.86808366551048
At round 197 accuracy: 0.6777546777546778
At round 197 training accuracy: 0.6693258632239206
At round 197 training loss: 1.0085620626278171
gradient difference: 77.42455310289878
At round 198 accuracy: 0.6517671517671517
At round 198 training accuracy: 0.6548322270263687
At round 198 training loss: 0.9627298245087487
gradient difference: 79.4244596250869
At round 199 accuracy: 0.7182952182952183
At round 199 training accuracy: 0.7177394799342306
At round 199 training loss: 0.9684260075104366
gradient difference: 73.36069020624834
At round 200 accuracy: 0.7427234927234927
At round 200 training accuracy: 0.7543389562146032
